# Summer REU Project

(May 25, 2018)

Project Title (Tentative) : Toward developing a medical Natural Language Generation system using Deep Learning and Reinforcement Learning

Abstract

We aim to build a prototype framework for Natural Language Generation (NLG) for the medical field leveraging recent advances in Deep Learning and Reinforcement Learning. By defining the task of NLG as sequential decision-making process, we implement two baselines, one built upon Long Short-Term Memory (LSTM)-based Recurrent Neural Network (RNN) and the other with Monte Carlo Tree Search (MCTS). Later, other enhanced variants based on MCTS are further pursued while research focuses for roles of evaluation metric, target corpus, and algorithmic benefits, etc are actively undertaking.

I. References

* LSTM RNN o Karpathy’s blog for RNN : http://karpathy.github.io/2015/05/21/rnn-effectiveness/

o Main Reference for LSTM-based sequence generation (baseline model I) : Graves, A. (2013). Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850.

o (More to come)

* MCTS

o MCTS-based Natural Language Generation (baseline model II) : Kumagai, K., Kobayashi, I., Mochihashi, D., Asoh, H., Nakamura, T., & Nagai, T. (2016). Human-like Natural Language Generation Using Monte Carlo Tree Search. In Proceedings of the INLG 2016 Workshop on Computational Creativity in Natural Language Generation (pp. 11-18).

o (More to come)

* Deep Reinforcement learning

o Some sort of Introduction (Only for fun and your knowledge) * https://deepmind.com/ * (Just one hit randomly) https://www.wired.com/story/greedy-brittle-opaque-and-shallow-the-downsides-to-deep-learning/

o (More to come)

II. Research Project

A. Deep Learning

* Artificial Neural Network models (since 2006, emphasized in its deep architecture)

o End-to-end training with backpropagation

o Scalable for large datasets

* Great performance for human-like perception problems (vision, NLP, audio, speech, etc). *biological sequences such as genomic and proteins. *some interests on graph datasets

* Machine Learning framework with representation learning, offering effective methods for unsupervised learning and other advanced methods such as meta learning, transfer learning, active learning, multi-task learning, multi modal learning, etc

* Deep Reinforcement Learning

o Deep Learning topics with Reinforcement Learning techniques

o Reinforcement Learning combined with Deep Learning-based function approximation

* Types of Deep Learning

o DNN, RNN, CNN, and my hybrid or complex architectures

o RNN – Long Short-Term Memory (LSTM)

B. Monte Carlo Tree Search and Reinforcement Learning

· MDP vs. POMDP

(more to come)

* Monte-Carlo Tree Search

(more to come)

Supp. Technical training

Pre-requisite

* PyTorch

* Spacy

* GitHub

* Jupyter

* Anadonda/PIP (Home Brew for Mac)

* Linux commands : ssh, etc

* Programming Development Environment Tool: ex) Microsoft Visual Studio Code

Note : there are numerous tutorials and youtube clips you can watch for more information. And, the most efficient way to master and to remember what you know is to repeat the same thing many times!

A. GitHub https://www.atlassian.com/git?utm_source=basic-git-commands&utm_medium=link&utm_campaign=git-microsite&_ga=2.75964245.1174987269.1527087707-1877757822.1527087707

* Our repository location : http://github.com/sdaysmerrill/Summer-REU-Project/

B. Python

· Shell vs. Jupyter notebook

· Package management with conda and pip

https://pip.pypa.io/en/stable/

· Environment with anaconda https://conda.io/docs/_downloads/conda-cheatsheet.pdf

C. Jupyter
